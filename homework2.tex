\documentclass[12pt]{article}

% The preamble file contains all the macros and page setup. I recommend making a folder where you compile your exercises and always call on the preamble.
\input{preamble}

% Here you can define your own macros
\newcommand{\calF}{\ensuremath{\mathcal{F}}}

\begin{document}
 
 %To create a header for the document use the following macro. \student{Homework number}{Name}

 \student{2}{Stefan Reschke}

 \sol{1} (a) We proof given cases of the definition. \begin{enumerate}
 	\item If $a$ and $b$ are even numbers, we have \begin{align}
 		\texttt{gcd}(a,b) &= \texttt{gcd}\bigg(2\cdot\frac{a}{2},2\cdot\frac{b}{2}\bigg) \\
 		&=2\cdot\texttt{gcd}\bigg(\frac{a}{2},\dfrac{b}{2}\bigg),
 	\end{align} which works, because $\frac{a}{2},\frac{b}{2}\in\mathbb{N}$.
 	\item If $a$ is odd and $b$ is even, we have \begin{align}
 		\texttt{gcd}(a,b)&=\texttt{gcd}\bigg(a,2\cdot\frac{b}{2}\bigg) \\
 		&=\texttt{gcd}\bigg(a,\frac{b}{2}\bigg)\cdot\texttt{gcd}(a,2).
 	\end{align} Since $a$ is odd, we know that $\texttt{gcd}(a,2)=1$. Thus \begin{equation}
 		\label{gcd:rule2}\texttt{gcd}(a,b)=\texttt{gcd}\bigg(a,\frac{b}{2}\bigg).
 	\end{equation}
 	\item If both $a$ and $b$ are odd, we observe \begin{equation}
 		\texttt{gcd}(a,b)=\begin{cases}
 			\texttt{gcd}(a-b,b) & a > b \\
 			\texttt{gcd}(b-a,b) & a < b.
 		\end{cases}
 	\end{equation} Thus, we have \begin{equation}
 		\texttt{gcd}(a,b)=\texttt{gcd}(|a-b|, b),
 	\end{equation} and know that $|a-b|$ is even whereas $b$ is odd. We apply \autoref{gcd:rule2} and conclude \begin{equation}
 		\texttt{gcd}(a,b)=\texttt{gcd}(|a-b|,b)=\texttt{gcd}\bigg(\dfrac{|a-b|}{2},b\bigg),
 	\end{equation} which was to be shown.
 \end{enumerate}

 (b) Using the above rule, the algorithm in \autoref{algo:1} can be used.
 
 (c) Since the algorithm involves recursion, we have \begin{equation}
 	T(n) = T(n/2) + \mathcal{O}(1)
 \end{equation} which gives a overall running time of \begin{equation}
 	T(n)\in\mathcal{O}(n\log n)
 \end{equation} by the Master theorem, if all operations performed take constant time. We have the following operations: \begin{enumerate}
 	\item \textbf{checks whether a number is even or odd,} which is a matter of looking at the last binary digit,
 	\item \textbf{dividing by two,} which is a matter of bitshifting,
 	\item \textbf{subtracting the two values,} which actually might be of linear complexity and reduce us to $\mathcal{O}(n^2)$.
 \end{enumerate}

 
\begin{lstlisting}[caption={Divide and conquer \texttt{gcd}},label={algo:1}]
Name: GCD_DC
Input: natural numbers a,b
Output: gcd(a,b)

if a=0: return b
if b=0: return a
if a even and b even: return 2*GCD_DC(a/2, b/2)
if a odd and b even: return GCD_DC(a, b/2)
if a even and b odd: return GCD_DC(a/2, b)
m := max(a, b)
l := min(a, b)
return GCD_DC(|m-l|/2, l)
\end{lstlisting}

 \sol{2} To save time, we only do (b), because \begin{equation}
 	\forall f:\ f\in\mathcal{O}(n)\rightarrow f\in\mathcal{O}(n\log n),
 \end{equation} thus every solution to (b) will also be a solution to (a).
 
 (a, b) We can use the algorithm in \autoref{algo:2}.
 
 \textbf{Is it correct?} If $v$ is 0 after the loop, there is no majority element. If $v$ is positive, $c$ is a exclusive candidate for being a majority element of $a$. The verification is done by the second loop.
 
 \textbf{How fast is it?} Since all operations take constant time, we only have the two loops, thus $\mathcal{O}(n)$.
 
 \textbf{Can we do better?} Unsure.
 
\begin{lstlisting}[caption={Finding majority elment in an array},label={algo:2}]
Name: majority_element
Input: array a
Output: candidate for majority element in a
v := 0.
c := ~.
for each p in a:
	if v = 0:
		c := p
		v := 1
	else:
		if p = c: v := v+1
		else: v := v-1.
if v > 0:
	count := 0.
	for each p in a:
		if p = c: count := count + 1.
	if count > #a/2: return c
else return omega.	
\end{lstlisting}

 \sol{3} We can use \href{https://en.wikipedia.org/wiki/Counting_sort}{counting sort}. We can beat the $\Omega(n\log n)$ bound, because the given $M$ is sufficiently small. If $M$ is large, counting sort will take much more time than using a comparison-based sorting algorithm.
 
 \sol{4} We can sort the array using \textbf{merge sort}. E.g. if we sort \begin{equation*}
 	[1, 5, 3, 7, 2, 8, 6, 4]
 \end{equation*} and take a look at the main call of \texttt{mergesort}, which splits this array up into two parts \begin{equation*}
 	[1, 5, 3, 7],\  [2, 8, 6, 4],
 \end{equation*} which after the recursive calls are themselves sorted, thus we have \begin{equation*}
 	[1, 3, 5, 7],\  [2, 4, 6, 8],
 \end{equation*} before the last call of \texttt{merge}. If \texttt{merge} merges the right side into the left one, we get to sort 2 between 1 and 3, resulting in: \begin{equation*}
 	[1, 2, 3, 5, 7], [4, 6, 8].
 \end{equation*} Now the number of elements in the left side that are bigger than 2 (which are 3, 5 and 7), gives as the count of inversions involving the 2 in this recursion step (which are 3), because the pairs $\langle 3,2\rangle$, $\langle 5,2\rangle$ and $\langle 7,2\rangle$ are inversions.
 
 If we append this value to the returned value of \texttt{merge} (and \texttt{mergesort}), we can add up all found inversions over the other recursion steps.
 
 Note: The version $\langle 8,6\rangle$ e.g. will be counted during $\texttt{mergesort}([2, 8, 6, 4])$ when the arrays $[2,8]$ and $[4, 6]$ (especially the 6) are merged. This way we don't lose any inversions.
 
 \vspace{.5cm}
 \textbf{Is it correct?} As stated, yes!
 
 \textbf{How much time does it take?} As \texttt{mergesort} is $\mathcal{O}(n\log n)$ and we only add primitive operations (additions namely, which are $\mathcal{O}(n)$), we stay at $\mathcal{O}(n\log n)$.
 
 \textbf{Can we do better?} Not in the scope of this task, I think.

 
 
 
\end{document}
